{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 统计学习方法（第一版） 习题解答\n",
    "**撰写人：**胡锐锋-天国之影-Relph  \n",
    "**github地址：**https://github.com/datawhalechina/statistical-learning-method-solutions-manual\n",
    "\n",
    "## 第1章统计学习方法概论-习题\n",
    "\n",
    "### 习题1.1\n",
    "&emsp;&emsp;说明伯努利模型的极大似然估计以及贝叶斯估计中的统计学习方法三要素。伯努利模型是定义在取值为0与1的随机变量上的概率分布。假设观测到伯努利模型$n$次独立的数据生成结果，其中$k$次的结果为1，这时可以用极大似然估计或贝叶斯估计来估计结果为1的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**\n",
    "\n",
    "伯努利模型的极大似然估计以及贝叶斯估计中的**统计学习方法三要素**如下：  \n",
    "1. **极大似然估计**  \n",
    "**模型：** $\\mathcal{F}=\\{f|f_p(x)=p^x(1-p)^{(1-x)}\\}$  \n",
    "**策略：** 最大化似然函数  \n",
    "**算法：** $\\displaystyle \\mathop{\\arg\\min}_{p} L(p)= \\mathop{\\arg\\min}_{p} \\binom{n}{k}p^k(1-p)^{(n-k)}$\n",
    "2. **贝叶斯估计**  \n",
    "**模型：** $\\mathcal{F}=\\{f|f_p(x)=p^x(1-p)^{(1-x)}\\}$  \n",
    "**策略：** 求参数期望  \n",
    "**算法：**\n",
    "$$\\begin{aligned}  E_\\pi\\big[p \\big| y_1,\\cdots,y_n\\big]\n",
    "& = {\\int_0^1}p\\pi (p|y_1,\\cdots,y_n) dp \\\\\n",
    "& = {\\int_0^1} p\\frac{f_D(y_1,\\cdots,y_n|p)\\pi(p)}{\\int_{\\Omega}f_D(y_1,\\cdots,y_n|p)\\pi(p)dp}dp \\\\\n",
    "& = {\\int_0^1}\\frac{p^{k+1}(1-p)^{(n-k)}}{\\int_0^1 p^k(1-p)^{(n-k)}dp}dp\n",
    "\\end{aligned}$$\n",
    "\n",
    "**伯努利模型的极大似然估计：**  \n",
    "定义$P(Y=1)$概率为$p$，可得似然函数为：$$L(p)=f_D(y_1,y_2,\\cdots,y_n|\\theta)=\\binom{n}{k}p^k(1-p)^{(n-k)}$$方程两边同时对$p$求导，则：$$\\begin{aligned}\n",
    "0 & = \\binom{n}{k}[kp^{k-1}(1-p)^{(n-k)}-(n-k)p^k(1-p)^{(n-k-1)}]\\\\\n",
    "& = \\binom{n}{k}[p^{(k-1)}(1-p)^{(n-k-1)}(m-kp)]\n",
    "\\end{aligned}$$可解出$p$的值为$p=0,p=1,p=k/n$，显然$\\displaystyle P(Y=1)=p=\\frac{k}{n}$  \n",
    "\n",
    "**伯努利模型的贝叶斯估计：**  \n",
    "定义$P(Y=1)$概率为$p$，$p$在$[0,1]$之间的取值是等概率的，因此先验概率密度函数$\\pi(p) = 1$，可得似然函数为： $$L(p)=f_D(y_1,y_2,\\cdots,y_n|\\theta)=\\binom{n}{k}p^k(1-p)^{(n-k)}$$  \n",
    "根据似然函数和先验概率密度函数，可以求解$p$的条件概率密度函数：$$\\begin{aligned}\\pi(p|y_1,\\cdots,y_n)&=\\frac{f_D(y_1,\\cdots,y_n|p)\\pi(p)}{\\int_{\\Omega}f_D(y_1,\\cdots,y_n|p)\\pi(p)dp}\\\\\n",
    "&=\\frac{p^k(1-p)^{(n-k)}}{\\int_0^1p^k(1-p)^{(n-k)}dp}\\\\\n",
    "&=\\frac{p^k(1-p)^{(n-k)}}{B(k+1,n-k+1)}\n",
    "\\end{aligned}$$所以$p$的期望为：$$\\begin{aligned}\n",
    "E_\\pi[p|y_1,\\cdots,y_n]&={\\int}p\\pi(p|y_1,\\cdots,y_n)dp \\\\\n",
    "& = {\\int_0^1}\\frac{p^{(k+1)}(1-p)^{(n-k)}}{B(k+1,n-k+1)}dp \\\\\n",
    "& = \\frac{B(k+2,n-k+1)}{B(k+1,n-k+1)}\\\\\n",
    "& = \\frac{k+1}{n+2}\n",
    "\\end{aligned}$$\n",
    "$\\therefore \\displaystyle P(Y=1)=\\frac{k+1}{n+2}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 习题1.2\n",
    "&emsp;&emsp;通过经验风险最小化推导极大似然估计。证明模型是条件概率分布，当损失函数是对数损失函数时，经验风险最小化等价于极大似然估计。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**解答：**\n",
    "\n",
    "假设模型的条件概率分布是$P_{\\theta}(Y|X)$，现推导当损失函数是对数损失函数时，极大似然估计等价于经验风险最小化。\n",
    "极大似然估计的似然函数为：$$L(\\theta)=\\prod_D P_{\\theta}(Y|X)$$两边取对数：$$\\ln L(\\theta) = \\sum_D \\ln P_{\\theta}(Y|X) \\\\ \n",
    "\\mathop{\\arg \\max}_{\\theta} \\sum_D \\ln P_{\\theta}(Y|X) = \\mathop{\\arg \\min}_{\\theta} \\sum_D (- \\ln P_{\\theta}(Y|X))$$ \n",
    "反之，经验风险最小化等价于极大似然估计，亦可通过经验风险最小化推导极大似然估计。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1.0,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "273.188px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
